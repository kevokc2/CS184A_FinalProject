{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6984590,"sourceType":"datasetVersion","datasetId":4014175},{"sourceId":992,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":846}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ReLU, MaxPool2D, GlobalAvgPool2D\nfrom tensorflow.keras.layers import Input, Add, ZeroPadding2D, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-08T04:09:23.577054Z","iopub.execute_input":"2023-12-08T04:09:23.577550Z","iopub.status.idle":"2023-12-08T04:09:40.762007Z","shell.execute_reply.started":"2023-12-08T04:09:23.577516Z","shell.execute_reply":"2023-12-08T04:09:40.760498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"supp_dir = '/kaggle/input/ubc-ovarian-cancer-competition-supplemental-masks'\ndata_dir = '/kaggle/input/UBC-OCEAN'\n\ntrain_csv = pd.read_csv(data_dir + '/train.csv')\ntest_csv = pd.read_csv(data_dir + '/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:11:52.638178Z","iopub.execute_input":"2023-12-08T04:11:52.639060Z","iopub.status.idle":"2023-12-08T04:11:52.669085Z","shell.execute_reply.started":"2023-12-08T04:11:52.639017Z","shell.execute_reply":"2023-12-08T04:11:52.667727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filter for WSI\ntrain_csv = train_csv[train_csv['is_tma'] == False]\ntrain_data, val_data = train_test_split(train_csv, test_size=0.2, random_state=42)\n\n#image paths\ntrain_image_paths = [data_dir + '/train_thumbnails/' + str(img_id) + '_thumbnail.png' for img_id in train_data['image_id']]\nval_image_paths = [data_dir + '/train_thumbnails/' + str(img_id) + '_thumbnail.png' for img_id in val_data['image_id']]\ntest_image_paths = [data_dir + '/test_thumbnails/' + str(img_id) + '_thumbnail.png' for img_id in test_csv['image_id']]\n\n#multi-class classification: encoding labels for model (one-hot encoding)\none_hot_encoder = OneHotEncoder(sparse_output=False)\n\n# Reshape the labels to a 2D array before applying OneHotEncoder\ntrain_labels = np.array(train_data['label'])\nval_labels = np.array(val_data['label'])\n\ntrain_labels_reshaped = train_labels.reshape(-1, 1)\nval_labels_reshaped = val_labels.reshape(-1, 1)\n\ntrain_labels_one_hot = one_hot_encoder.fit_transform(train_labels_reshaped)\nval_labels_one_hot = one_hot_encoder.transform(val_labels_reshaped)\n\n\n#print(test_labels_one_hot)\n#print(val_labels_one_hot)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:11:53.803867Z","iopub.execute_input":"2023-12-08T04:11:53.804277Z","iopub.status.idle":"2023-12-08T04:11:53.849462Z","shell.execute_reply.started":"2023-12-08T04:11:53.804246Z","shell.execute_reply":"2023-12-08T04:11:53.848086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(1) feature scales first (all pixel values are now between 0 and 1), image augmentation transforms (shear_range, zoom_range, horizontal_flip) to prevent overfitting\ndatagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   #zoom_range = 0.2,\n                                   horizontal_flip = True\n                            )\n\ndef load_and_augment_img(img_path):\n    img = Image.open(img_path)\n    img = img.resize((224, 224))  # Resize to desired dimensions\n    img = np.array(img)  # Convert to numpy array\n    img = img.reshape((1,) + img.shape)  # Reshape to (1, height, width, channels) for flow()\n    img = datagen.flow(img, batch_size=1).next()  # Apply data augmentation\n    return img[0]\n\n# Apply data augmentation to training, validation, and test images\ntrain_images_augmented = [load_and_augment_img(path) for path in train_image_paths]\nval_images_augmented = [load_and_augment_img(path) for path in val_image_paths]\ntest_images_augmented = [load_and_augment_img(path) for path in test_image_paths]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:11:54.813391Z","iopub.execute_input":"2023-12-08T04:11:54.813845Z","iopub.status.idle":"2023-12-08T04:14:36.593141Z","shell.execute_reply.started":"2023-12-08T04:11:54.813806Z","shell.execute_reply":"2023-12-08T04:14:36.591794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef visualize(image):\n    plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:15.972793Z","iopub.execute_input":"2023-12-06T01:11:15.973734Z","iopub.status.idle":"2023-12-06T01:11:15.979024Z","shell.execute_reply.started":"2023-12-06T01:11:15.973659Z","shell.execute_reply":"2023-12-06T01:11:15.977958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=train_image_paths[0], width=768, height=768) ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:15.980118Z","iopub.execute_input":"2023-12-06T01:11:15.980465Z","iopub.status.idle":"2023-12-06T01:11:16.323806Z","shell.execute_reply.started":"2023-12-06T01:11:15.980434Z","shell.execute_reply":"2023-12-06T01:11:16.318875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize(train_images_augmented[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:16.328419Z","iopub.execute_input":"2023-12-06T01:11:16.330227Z","iopub.status.idle":"2023-12-06T01:11:16.569456Z","shell.execute_reply.started":"2023-12-06T01:11:16.330160Z","shell.execute_reply":"2023-12-06T01:11:16.568220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define ResNet-50 Architecture","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:42:29.171904Z","iopub.execute_input":"2023-12-02T19:42:29.172298Z","iopub.status.idle":"2023-12-02T19:42:29.201763Z","shell.execute_reply.started":"2023-12-02T19:42:29.172269Z","shell.execute_reply":"2023-12-02T19:42:29.200849Z"}}},{"cell_type":"code","source":"unique_classes = np.unique(train_labels)\nuni_classes = list(unique_classes)\nlength = len(unique_classes)\n\nprint(uni_classes)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:14:45.065269Z","iopub.execute_input":"2023-12-08T04:14:45.065690Z","iopub.status.idle":"2023-12-08T04:14:45.072419Z","shell.execute_reply.started":"2023-12-08T04:14:45.065659Z","shell.execute_reply":"2023-12-08T04:14:45.071423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = (224, 224, 3)\nNUMBER_OF_CLASSES = 5","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:14:45.963986Z","iopub.execute_input":"2023-12-08T04:14:45.964430Z","iopub.status.idle":"2023-12-08T04:14:45.971120Z","shell.execute_reply.started":"2023-12-08T04:14:45.964395Z","shell.execute_reply":"2023-12-08T04:14:45.969515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFINE THE RESNET-50 ARCHITECTURE *************************************************************\n\ndef conv_batchnorm_relu(x, filters, kernel_size, strides=1):\n    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\n\ndef identity_block(tensor, filters):\n    x = conv_batchnorm_relu(tensor, filters=filters, kernel_size=1, strides=1)\n    x = conv_batchnorm_relu(x, filters=filters, kernel_size=3, strides=1)\n    x = Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n    x = BatchNormalization()(x)\n    x = Add()([tensor,x]) \n    x = ReLU()(x)\n    return x\n\ndef projection_block(tensor, filters, strides):\n    x = conv_batchnorm_relu(tensor, filters=filters, kernel_size=1, strides=strides)     \n    x = conv_batchnorm_relu(x, filters=filters, kernel_size=3, strides=1)     \n    x = Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)     \n    x = BatchNormalization()(x) \n    shortcut = Conv2D(filters=4*filters, kernel_size=1, strides=strides)(tensor)     \n    shortcut = BatchNormalization()(shortcut)          \n    x = Add()([shortcut,x])       \n    x = ReLU()(x)          \n    return x \n    \ndef resnet_block(x, filters, reps, strides):\n    x = projection_block(x, filters, strides)\n    for _ in range(reps-1):\n        x = identity_block(x,filters)\n    return x ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:15:36.078699Z","iopub.execute_input":"2023-12-08T04:15:36.079735Z","iopub.status.idle":"2023-12-08T04:15:36.093779Z","shell.execute_reply.started":"2023-12-08T04:15:36.079695Z","shell.execute_reply":"2023-12-08T04:15:36.092096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = Input(shape=input_tensor)\n\n\nx = conv_batchnorm_relu(input, filters=64, kernel_size=7, strides=2)\nx = MaxPool2D(pool_size=3, strides=2)(x)\nx = resnet_block(x, filters=64, reps=3, strides=1)\nx = resnet_block(x, filters=128, reps=4, strides=2)\nx = resnet_block(x, filters=256, reps=6, strides=2)\nx = resnet_block(x, filters=512, reps=3, strides=2)\nx = GlobalAvgPool2D()(x)\n\n\noutput = Dense(NUMBER_OF_CLASSES, activation ='softmax')(x)\n\n\nmodel = Model(inputs=input, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T04:15:40.543029Z","iopub.execute_input":"2023-12-08T04:15:40.543867Z","iopub.status.idle":"2023-12-08T04:15:42.418409Z","shell.execute_reply.started":"2023-12-08T04:15:40.543817Z","shell.execute_reply":"2023-12-08T04:15:42.417117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:18.367003Z","iopub.execute_input":"2023-12-06T01:11:18.367369Z","iopub.status.idle":"2023-12-06T01:11:18.810557Z","shell.execute_reply.started":"2023-12-06T01:11:18.367336Z","shell.execute_reply":"2023-12-06T01:11:18.809499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom tensorflow.keras.utils import plot_model\n\nplot_model(model)\n'''\n# NOTE: Dont run this cell unless you want to visually see a graph of network","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:18.813306Z","iopub.execute_input":"2023-12-06T01:11:18.813654Z","iopub.status.idle":"2023-12-06T01:11:18.820340Z","shell.execute_reply.started":"2023-12-06T01:11:18.813623Z","shell.execute_reply":"2023-12-06T01:11:18.819151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n#from tensorflow.keras.callbacks import EarlyStopping\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n\nresults = model.fit(\n    np.array(train_images_augmented), train_labels_one_hot,\n    epochs=15, \n    batch_size=32,\n    validation_data=(np.array(val_images_augmented), val_labels_one_hot ),\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:11:18.822889Z","iopub.execute_input":"2023-12-06T01:11:18.823400Z","iopub.status.idle":"2023-12-06T01:45:17.144455Z","shell.execute_reply.started":"2023-12-06T01:11:18.823361Z","shell.execute_reply":"2023-12-06T01:45:17.143172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SUBMISSION FILE\n\npred = model.predict(np.array(test_images_augmented))\ntest = np.argmax(pred,axis=1)\npredicted_labels = [uni_classes[i] for i in test]\n\nsubmission = [[test_csv[\"image_id\"][i], predicted_labels[i]] for i in range(len(test_csv)) ]\ndf = pd.DataFrame(submission,columns = [\"image_id\",\"label\"])\n\ndf.to_csv(\"submission.csv\", index=False)\n\n#PLOTTING ACCURACY AND LOSS GRAPHS\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\naxes[0].plot(results.history['accuracy'], label = 'Training')\naxes[0].plot(results.history['val_accuracy'], label = 'Validation')\n\naxes[0].set_title(\"Model accuracy\")\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy rate')\n\naxes[0].legend()  \n\naxes[1].plot(results.history['loss'], label = 'Training')\naxes[1].plot(results.history['val_loss'], label = 'Validation')\n\naxes[1].set_title(\"Model loss\")\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\n\ntraining_accuracy = results.history['accuracy']\nvalidation_accuracy = results.history['val_accuracy']\n\noverall_training_accuracy = sum(training_accuracy) / len(training_accuracy)\noverall_validation_accuracy = sum(validation_accuracy) / len(validation_accuracy)\n\nprint(f\"Overall Training Accuracy: {overall_training_accuracy}%\")\nprint(f\"Overall Validation Accuracy: {overall_validation_accuracy}%\")\n\nplt.legend()  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:45:17.146349Z","iopub.execute_input":"2023-12-06T01:45:17.147143Z","iopub.status.idle":"2023-12-06T01:45:21.729367Z","shell.execute_reply.started":"2023-12-06T01:45:17.147099Z","shell.execute_reply":"2023-12-06T01:45:21.728134Z"},"trusted":true},"execution_count":null,"outputs":[]}]}